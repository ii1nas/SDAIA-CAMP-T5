{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["---\n","---\n","# Perceptron\n","---\n","---\n","\n","This notebook demonstrates the application of the Perceptron algorithm for classifying handwritten digits from the MNIST dataset.\n","\n","The perceptron model is a type of artificial neural network invented in 1958 by Frank Rosenblatt. It is one of the earliest and simplest types of artificial neural networks, and forms the foundational building block for more complex networks. The model is based on a supervised learning algorithm used for binary classifiers, which means it is capable of classifying an input into one of two possible classes.\n","\n","[Further Reading](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html)"],"metadata":{"id":"3XVsZ4LwjJMs"}},{"cell_type":"markdown","source":["## Libraries Import"],"metadata":{"id":"QSzCpd7GsIUG"}},{"cell_type":"code","source":["#importing\n","from sklearn.datasets import fetch_openml\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import Perceptron\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"ZYtnh2qokzYk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Loading:\n","    - Utilizes `fetch_openml` from `sklearn.datasets` to import the MNIST dataset.\n","    - Separates the data into features (`X`) and labels (`y`).\n","    - Converts labels to integers for compatibility."],"metadata":{"id":"kJGdxFW5WK5H"}},{"cell_type":"markdown","source":["**MNIST Dataset:**\n","The MNIST dataset is a large database of handwritten digits commonly used for training various image processing systems. It contains 70,000 images of handwritten digits from 0 to 9, making it a staple dataset for benchmarking classification algorithms.\n","\n","![MNIST Sample](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n"],"metadata":{"id":"WLMdjvIEWFK2"}},{"cell_type":"code","source":["#Loading The Data\n","#Load MNIST dataset\n","mnist = fetch_openml('mnist_784', version=1)\n","X, y = mnist[\"data\"], mnist[\"target\"]\n","# Convert labels to integers\n","y = y.astype(int)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7A1_Q1gjRH2","executionInfo":{"status":"ok","timestamp":1713087748276,"user_tz":-120,"elapsed":66382,"user":{"displayName":"Mohamed Eldeeb","userId":"14305021883410993794"}},"outputId":"95c009b5-3d13-45ae-be2f-78ab4876ee70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n","  warn(\n"]}]},{"cell_type":"markdown","source":["\n","## Data Splitting:\n","    - Employs `train_test_split` from `sklearn.model_selection` to divide the data into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`) sets."],"metadata":{"id":"8RT1YMnUV0x5"}},{"cell_type":"code","source":["# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"y6YrkCLrjZXq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## Model Creation and Training:\n","    - Creates a Perceptron model with specified parameters:\n","        - `max_iter`: Maximum number of iterations for training.\n","        - `eta0`: Learning rate.\n","        - `random_state`: Seed for random number generator.\n","    - Trains the model using the training data (`X_train`, `y_train`)."],"metadata":{"id":"AQytsvdrWYil"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"id":"LCSeF2HXPL5q","executionInfo":{"status":"ok","timestamp":1713087764668,"user_tz":-120,"elapsed":15762,"user":{"displayName":"Mohamed Eldeeb","userId":"14305021883410993794"}},"outputId":"9f8de51b-6de3-4064-f1ea-c86c44da71cd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Perceptron(eta0=0.1, max_iter=100, random_state=42)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron(eta0=0.1, max_iter=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron(eta0=0.1, max_iter=100, random_state=42)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":4}],"source":["# Create and train Perceptron model\n","perceptron = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n","perceptron.fit(X_train, y_train)"]},{"cell_type":"markdown","source":["## Prediction and Evaluation:\n","    - Predicts labels for the test data (`X_test`) using the trained model.\n","    - Calculates the accuracy of the predictions by comparing them with the actual labels (`y_test`) from the test set.\n","    - Prints the accuracy and the classification report, which provides detailed information about the performance of the model for each class."],"metadata":{"id":"DvDmUPfSWamu"}},{"cell_type":"code","source":["# Predict on test set\n","y_pred = perceptron.predict(X_test)"],"metadata":{"id":"gbR3YM0ejirS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"id":"6Wl5fVBfQker","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713087764669,"user_tz":-120,"elapsed":8,"user":{"displayName":"Mohamed Eldeeb","userId":"14305021883410993794"}},"outputId":"d57b7522-4f32-4415-95cd-6a4a4985d5ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8645714285714285\n"]}]},{"cell_type":"code","source":["# prompt: print accuracy report\n","\n","from sklearn.metrics import classification_report\n","\n","# Print the classification report\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lmrAO6tj0oE","executionInfo":{"status":"ok","timestamp":1713087764669,"user_tz":-120,"elapsed":6,"user":{"displayName":"Mohamed Eldeeb","userId":"14305021883410993794"}},"outputId":"ca6ab87c-d7f0-419d-8981-356a4f6a3f49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.84      0.98      0.90      1343\n","           1       0.96      0.95      0.95      1600\n","           2       0.91      0.81      0.86      1380\n","           3       0.89      0.84      0.87      1433\n","           4       0.88      0.87      0.87      1295\n","           5       0.93      0.66      0.77      1273\n","           6       0.95      0.94      0.94      1396\n","           7       0.96      0.80      0.87      1503\n","           8       0.71      0.87      0.78      1357\n","           9       0.73      0.91      0.81      1420\n","\n","    accuracy                           0.86     14000\n","   macro avg       0.87      0.86      0.86     14000\n","weighted avg       0.88      0.86      0.86     14000\n","\n"]}]},{"cell_type":"markdown","source":["\n","In summary, this notebook showcases the use of the Perceptron algorithm for classifying handwritten digits from the MNIST dataset. It demonstrates the process of training the model, making predictions, and evaluating its performance."],"metadata":{"id":"AN7J5qD8WePT"}},{"cell_type":"code","source":[],"metadata":{"id":"UgNCMcbEWfgU"},"execution_count":null,"outputs":[]}]}